#' Make raw Counts table from Sports output
#'
#'\code{make_counts} uses parallel processing to generate a raw countTable.
#'
#' Given a list of imported Sports output data.frames (generated by
#' \code{import_sports}), and an annotation file (generated by \code{make_anno}
#' this function will generate a raw countTable (columns=sample, rows=sequence).
#'
#' @family PAC generation
#'
#' @seealso \url{https://github.com/junchaoshi/sports1.0} for download and
#'   documentation about running Sports. \url{https://github.com/Danis102} for
#'   updates on the current package.
#'
#' @param input If type="fastq" the input is a path to a directory containing
#'   input fastq-files. The script will recursively search this directory for
#'   the .fastq|.fastq.gz extension. If type="sports" input is a list containing
#'   imported data frames from Sports output. This list can be generated using
#'   \code{import_sports}.
#'
#' @param type Character indicating what input that should be used. If
#'   type="fastq", the scripts will generate a count table based on fastq files
#'   stored in the input path. If type="sports", a count table is generated from
#'   a list object created using \code{import_sports} contain imported sports
#'   output files .
#'   
#' @param anno Annotation dataframe generated by makeAnno (type="sports"). This
#'   parameter must be set to NULL if type="fastq" (default=NULL).
#'
#' @param threads Integer stating the number of parallell jobs. Note, that
#'   reading multiple fastq files drains memory fast, using up to 10Gb per fastq
#'   file. To avoid crashing the system due to memory shortage, make sure that
#'   each thread on the machine have at least 10 Gb of memory availabe, unless
#'   your fastq files are very small.Use \code{parallel::detectcores()} to see
#'   available threads on the machine.
#'
#' @param par_type Character indicating what type of parallel processing that
#'   should be used. If par_type="PSOCK" parallel socket clustering is used
#'   (Windows/Linux/Mac). If par_type="FORK", branching forks are used
#'   (Linux/Mac). Default="PSOCK".
#'
#' @param cutadpt Logical indicating if fastq files should be parsed to cutadapt
#'   and fastq_quality_filter (only available in Linux) for adaptor trimming and
#'   filtering prior to compiling a count table. If cutadpt=FALSE, the input
#'   path must contain already trimmed and quality filtered fastq files. If
#'   cutadpt=TRUE, trimming will be carried out using the commands in "parse",
#'   while quality filtering will be done using the following command:
#'   "fastq_quality_filter -q 20 -p 80 -v". Trimmed and filtered fastq files
#'   will be temporarly stored in "tmp/seqpac/", but will be deleted after the
#'   script has completed.
#'
#' @param parse Command strings defining the command that should be parsed to
#'   cutadapt using the system function in R. This will allow you to customize
#'   your timming according to 3' adaptor sequence and platform specifics etc.
#'   See examples below. Important: Do not include the two last options in
#'   cutadapt: -o (output path) and -i (input path). These will be generated
#'   automatically.
#'
#' @param tag Logical indicating whether 5' tagging has been used. This is
#'   specific to certain types of sequencing experiments, where beside a 3'
#'   adaptor a 5' tag has been ligated to the sequencing library. If tag=TRUE, a
#'   5' tag will be searched for only in the samples specified in 'target_tag'
#'   using the commands indicated in 'parse_tag'. Note that target_tag and
#'   parse_tag are lists, thus groups of samples can have different commands
#'   parsed to them. Example of how this can be done see below. Note that
#'   parsing these commands will be done after the 3' adaptor sequence has been
#'   trimmed off. This will be done on the fastq files If tag=FALSE, this step
#'   will be passed. 
#'
#' @param parse_tag A named list of command strings. Each object contains the
#'   command that are to be parsed to cutadapt, for splitting the input fastq
#'   file specified in 'target_tag' into fastq files containg (_tag.fastq) and
#'   not containing (_notag.fastq) the 5' tag. The 5' tag will also be trimmed
#'   from _tag.fastq files. Important: Do not include the two last options in
#'   cutadapt: -o (output path) and -i (input path). These will be generated
#'   automatically. Default=NULL.
#'
#' @param target_tag A named list of character vectors. Each vector should
#'   contain the the input fastq file names of which 5' tagging have been used.
#'   If different 5' tags, with different sequences, has been ligated to
#'   different samples,  this can be specified objects with the same names in
#'   'target_tag' and 'parse_tag' having the same names.  For example, if
#'   target_tag$short contains the fastq file names of sample_A and sample_D,
#'   the command in parse_tag$short will be applied only on these samples.
#'   Samples missing from 'target_tag', will pass 5' tagging. For an examples
#'   see below. Default=NULL.
#'   
#' @return 
#' type="fastq": Data frame (a count table) with sequence counts across
#' all samples of sequences that occured at least two independent samples.
#' 
#' type="sports" Using the weakly filtered master annotation file (anno)
#' generated by the \code{make_anno} function, \code{make_counTable} will
#' extract the target sequences in anno from sports_lst and merge the counts
#' into one single data.frame (raw countTable). The output data.frame will ahve
#' rownames matching the original master annotation file.
#' 
#' 
#'
#'
#' @examples
#'   
#'   ### Sports type ### 
#'   countTable <- make_counts2(input = <name_of_your_imported_sports_list>,
#'                       anno    = <name_of_your_annotation_dataframe>,
#'                       threads       = <number_of_independent_evidence>,
#'                       )
#'
#'   countTable <- make_count2(sports_lst = sports_lst, anno=anno, threads=12)
#'   
#'   
#'  ### Fastq type ### 
#'  Ph_grps <- read.delim("/data/Data_analysis/Projects/Drosophila/Other/IOR/Jan_IOR_200130/Groups_data.txt", header=TRUE)
#'  Ph_grps$Sample <-  gsub("_d|_s", "", Ph_grps$Sample_ID)
#'  Ph_grps <- Ph_grps[!duplicated(Ph_grps$Sample),]
#'  Ph_grps$Tag_type <- ifelse(grepl("Long", Ph_grps$Method), "Long", 
#'                              ifelse(grepl("Short", Ph_grps$Method), "Short", NA))
#'  
#'  input <-  "/data/Data_analysis/Projects/Drosophila/Other/IOR/Jan_IOR_200130"
#'  parse = "cutadapt -j 1 -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCACAT --discard-untrimmed --nextseq-trim=20 -O 5 -m 5"
#'  type="fastq"
#'  cutadpt =TRUE
#'  threads =8
#'  par_type="PSOCK"
#'  tag=TRUE
#'  
#'  parse_tag = list(  Long="cutadapt -j 1 -g TGGCAACGATC -O 5 -m 5", 
#'                         Short="cutadapt -j 1 -g TGGGATC -O 5 -m 5")
#'                         
#'  target_tag = list(  Long= gsub("_2", "-2", Ph_grps$Sample[Ph_grps$Tag_type %in% "Long"]),
#'                       Short= gsub("_2", "-2", Ph_grps$Sample[Ph_grps$Tag_type %in% "Short"]))
#'  
#'  test <- make_counts2(input, type=type, threads=threads, par_type=par_type, anno=NULL, cutadpt=cutadpt, parse=parse, tag=tag, parse_tag=parse_tag, target_tag=target_tag)
#'  
#' @export
make_counts2 <- function(input, type="fastq", threads, par_type="PSOCK", anno=NULL, cutadpt=FALSE, parse=NULL, tag=FALSE, parse_tag=NULL, target_tag=NULL){
                          require(foreach)
                          ### Sports as input
                          if(type=="sports"){
                                    sports_lst = input
                                    setDTthreads(threads=threads)
                                    cat("Generating a raw countTable from ", length(sports_lst), "sport output files over ", nrow(anno), "unique RNA sequences.\n")
                                    cat("Started at ", paste0(Sys.time()), "\n")
                                    ordCount_df <- data.frame(matrix(NA, nrow=nrow(anno), ncol=length(sports_lst)))
                                    pb <- txtProgressBar(min = 0, max = length(sports_lst), initial = 0, style = 3, width = 100)
                                    for(i in 1:length(sports_lst)){
                                              ordCount_df[,i]  <- sports_lst[[i]]$Reads[match(rownames(anno), as.character(sports_lst[[i]]$Sequence))]
                                              colnames(ordCount_df)[i] <- gsub("_merge", "", names(sports_lst)[i])
                                              Sys.sleep(0.001)
                                              setTxtProgressBar(pb,i)
                                    }
                                    rownames(ordCount_df) <- rownames(anno)
                                    for(j in 1:ncol(ordCount_df)){set(ordCount_df, which(is.na(ordCount_df[[j]])), j, 0)} # Replace NAs with 0s using set in data.table (paralell processing)
                                    cat("\nFinished at ", paste0(Sys.time()), "\n")
                                    }
                          
                          ### fastq as input
                          if(type=="fastq"){
                                    
                                    ## Parallel setup
                                    gc(reset=TRUE)
                                    cl <- parallel::makeCluster(threads, type = par_type)
                                    doParallel::registerDoParallel(cl)
                            
                                    ## Read file system
                                    path <- input
                                    count_files <- list.files(path, pattern ="fastq.gz\\>|fastq\\>", full.names=TRUE, recursive=TRUE)
                                    count_files_nams <- basename(count_files)
                                    cat("\nInput type was set to fastq.\n")
                                    cat("The following fastq files were found in the path:\n")
                                    print(count_files)
                                    
                                    ## Read and trim fastq files
                                    if(cutadpt==TRUE){
                                            cat("\n\nAdaptor trimming was specified.")
                                            cat("\nThis will work unless cutadapt and fastq_quality_filter have not been installed correctly.")
                                            system("cutadapt --version", intern=TRUE)
                                            system("cutadapt --version", intern=TRUE)
                                            cat(paste0("\nParsing fastq-files into cutadapt and then fastq_quality_filter using ", threads, " workers (this may take several minutes) ..."))
                                            suppressWarnings(dir.create("/tmp/seqpac"))
                                            fn <- list.files("/tmp/seqpac", full.names=TRUE, recursive=TRUE)
                                            if(any(file.exists(fn))){file.remove(fn)}

                                            foreach::foreach(i=1:length(count_files), .packages=c("ShortRead"), .final = function(x){names(x) <- basename(count_files); return(x)}) %dopar% {
                                                                system(paste0(parse, " -o /tmp/seqpac/temp", i, ".fastq ", count_files[i]), ignore.stdout = TRUE)

                                                            ## No tagging
                                                                if(tag==FALSE){
                                                                    system(paste0("fastq_quality_filter -q 20 -p 80 -v -i /tmp/seqpac/temp", i, ".fastq -o /tmp/seqpac/temp", i, ".fastq.gz -z"), ignore.stdout = TRUE)
                                                                    file.remove(paste0("/tmp/seqpac/temp", i, ".fastq"))
                                                                    }

                                                            ## Tagging
                                                                if(tag==TRUE){
                                                                      if(is.null(target_tag)){stop("You have to specify the names of the samples that are tagged in target_tag!\n       Hint: If all samples are tagged, add all samples names to target_tag")}
                                                                      spl_nam <- basename(count_files[i])
                                                                      if(grepl(paste0(do.call("c", target_tag), collapse="|"), spl_nam)){
                                                                                      parse_tag_logi <- do.call("c", lapply(target_tag, function(x){grepl(paste(x, collapse="|"), spl_nam)}))
                                                                                      parse_tag_nam <- names(parse_tag_logi)[parse_tag_logi==TRUE]
                                                                                      system(paste0(parse_tag[parse_tag_nam]," -o /tmp/seqpac/temp", i, "_tag.fastq --untrimmed-output /tmp/seqpac/temp", i, "_notag.fastq /tmp/seqpac/temp", i, ".fastq"), ignore.stdout = TRUE)
                                                                                      system(paste0("fastq_quality_filter -q 20 -p 80 -v -i /tmp/seqpac/temp", i, "_tag.fastq -o /tmp/seqpac/temp", i, "_tag.fastq.gz -z"), ignore.stdout = TRUE)
                                                                                      system(paste0("fastq_quality_filter -q 20 -p 80 -v -i /tmp/seqpac/temp", i, "_notag.fastq -o /tmp/seqpac/temp", i, "_notag.fastq.gz -z"), ignore.stdout = TRUE)
                                                                                      file.remove(paste0("/tmp/seqpac/temp", i, ".fastq"))
                                                                                      file.remove(paste0("/tmp/seqpac/temp", i, "_tag.fastq"))
                                                                                      file.remove(paste0("/tmp/seqpac/temp", i, "_notag.fastq"))
                                                                      }else{
                                                                                      system(paste0("fastq_quality_filter -q 20 -p 80 -v -i /tmp/seqpac/temp", i, ".fastq -o /tmp/seqpac/temp", i, ".fastq.gz -z"), ignore.stdout = TRUE)
                                                                                      file.remove(paste0("/tmp/seqpac/temp", i, ".fastq"))
                                                                                      }
                                                                }

                                            }
                                      cat("\nFinished generating trimmed temporary files.")
                                     }
                                      ## Read trimmed files
                                      cat("\nIdentifying unique sequences in trimmed fastq files...")
                                      if(cutadpt==FALSE){fls <- count_files}
                                      if(cutadpt==TRUE){fls <- list.files("/tmp/seqpac", pattern=".fastq.gz\\>", full.names=TRUE, recursive=FALSE)}
                                      cat("\n")

                                      save.image(file="/tmp/seqpac/temp.Rdata")
                                      .rs.restartR()  
                                      load(file="/tmp/seqpac/temp.Rdata")
                                      gc(reset=TRUE)
                                      seq_lst   <- foreach::foreach(i=1:length(fls), .packages=c("ShortRead"), .final = function(x){names(x) <- basename(count_files); return(x)}) %dopar% {
                                                              fstq <- ShortRead::readFastq(fls[[i]])
                                                              return(unique(paste0(ShortRead::sread(fstq))))
                                                              }
                                      cat("\nCompiling...")
                                      seqs <- do.call("c", seq_lst)
                                      rm(seq_lst)
                                      seqs_dup <- unique(as.character(seqs[duplicated(seqs)]))
                                      rm(seqs)

                                      ## Make count table
                                      cat("\nNow making a count table with sequences appearing in at least 2 independent samples...")
                                      reads_lst <- foreach::foreach(i=1:length(fls), .packages=c("ShortRead"), .final = function(x){names(x) <- basename(fls); return(x)}) %dopar% {
                                                                fstq <- ShortRead::readFastq(paste0(fls[i]))
                                                                reads <- paste0(ShortRead::sread(fstq))
                                                                rm(fstq)
                                                                reads_dup <- reads[reads %in% seqs_dup]
                                                                rm(reads)
                                                                n_reads <- data.table::as.data.table(table(reads_dup))
                                                                n_reads_mtch <- n_reads[match(seqs_dup, n_reads$reads_dup),]
                                                                rm(n_reads)
                                                                rownames(n_reads_mtch) <- seqs_dup
                                                                n_reads_mtch$N[is.na(n_reads_mtch$N)] <- 0 
                                                                stopifnot(identical(as.character(n_reads_mtch$reads_dup[!is.na(n_reads_mtch$reads_dup)]), as.character(rownames(n_reads_mtch)[!is.na(n_reads_mtch$reads_dup)])))
                                                                dt <- n_reads_mtch[,2]
                                                                rownames(dt) <- rownames(n_reads_mtch)
                                                                return(dt)
                                                          }
                                      cat("\nFinalizing...")
                                      sampl_nam <- gsub("_merge|\\.fastq|\\.gz", "", count_files_nams)
                                      sampl_nam <- gsub("-", "_", sampl_nam)
                                      if(cutadpt==TRUE){temp_nams <- do.call("rbind", strsplit(names(reads_lst), "\\."))[,1]
                                                        temp_num <- stringr::str_extract(temp_nams, "\\-*\\d+\\.*\\d*")
                                                        new_temp_nams <- sampl_nam[as.integer(temp_num)]
                                                        names(reads_lst) <- paste0(new_temp_nams, gsub("temp|\\d*", "", temp_nams))
                                                        fn <- list.files("/tmp/seqpac", full.names=TRUE, recursive=FALSE)
                                                        if(any(file.exists(fn))){file.remove(fn)}
                                                          }
                                      ordCount_df <- as.data.frame(do.call("cbind", reads_lst))
                                      colnames(ordCount_df) <- gsub("\\.N\\>", "", colnames(ordCount_df))
                                      rownames(ordCount_df) <- rownames(reads_lst[[1]])
                                      parallel::stopCluster(cl)
                                      }
                          return(ordCount_df)
                          }
