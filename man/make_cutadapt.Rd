% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/make_cutadapt.R
\name{make_cutadapt}
\alias{make_cutadapt}
\title{Trims/filter fastq using external cutadapt/fastq_quality_filter}
\usage{
make_cutadapt(input, output, parse = NULL, threads = 1)
}
\arguments{
\item{input}{Character path to a directory containing input fastq-files. The
script will recursively search this directory for the .fastq|.fastq.gz
extension.}

\item{output}{Character path to the output directory where trimmed fastq files
will be stored and temporary files will be generated.}

\item{parse}{List with two character string expressions. The first will be
parsed to cutadapt while the other is be parsed to fastq_quality_filter. If
any is NULL, then the function will not pass the command and the trimming or
filtering will not be applied. Thus, if parse = list(cutadapt=NULL,
fastq_quality_filter="-q 20 -p 80"), then only the quality filter will be
applied.}

\item{threads}{Integer stating the number of parallell jobs. Note, that
reading multiple fastq files drains memory fast, using up to 10Gb per fastq
file. To avoid crashing the system due to memory shortage, make sure that
each thread on the machine have at least 10 Gb of memory availabe, unless
your fastq files are very small. Use \code{parallel::detectcores()} to see
available threads on the machine.}
}
\value{
Externally the function will generate trimmed and/or quality filtered
fastq files in the output folder. Internally, a list of logs that can be used
to generate a progress report is returned.
}
\description{
\code{make_cuadapt} cutadapt/fastq_quality_filter
}
\details{
Given a path to sequence files in fastq format this function will trim adaptor
and remove sequences with low quality.
}
\examples{
 
\dontrun{  
############################################################      
### Seqpac trimming using the make_cutadapt function
### (Important: Needs an external installations of cutadapt 
###  and fastq_quality_filter) 
#  
   input = system.file("extdata", package = "seqpac", mustWork = TRUE)
   output =  "/some/path/to/temp/folder"
 
   output = "/home/danis31/Desktop/Temp"
 
 # Parse for make_cutadapt is a list of 2 character string expressions.
 # The first is parsed to cutadapt and the other to fastq_quality_filter 
 # For parallel processes '-j 1' is recommended since seqpac will   
 # parallelize across samples and not within.
 # Run system("cutadapt -h") and system("fastq_quality_filter -h") 
 # for more options.
 
 # String to parse to cutadapt:
 cut_prs <- paste0("-j 1 -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCACAT",
                   " --discard-untrimmed --nextseq-trim=20",
                   " -O 10 -m 7 -M 70")
 
 # Add string to parse to fastq_quality_filter:
 parse = list(
           cutadapt=cut_prs,
           fastq_quality_filter="-q 20 -p 80")
              
 logs  <-  make_cutadapt(input, output, threads=1, parse=parse)
 
 }
 
############################################################ 
### Seqpac fastq trimming with the make_trim function 
### (for more streamline options see the make_counts function) 

# First generate some smallRNA fastq.
# Only one untrimmed fastq comes with seqpac
# Thus, we need to randomly sample that one using the ShortRead-package
 
sys_path = system.file("extdata", package = "seqpac", mustWork = TRUE)
fq <- list.files(path = sys_path, pattern = "fastq", all.files = FALSE,
                full.names = TRUE)

closeAllConnections()

sampler <- ShortRead::FastqSampler(fq, 20000)
set.seed(123)
fqs <- list(fq1=ShortRead::yield(sampler),
           fq2=ShortRead::yield(sampler),
           fq3=ShortRead::yield(sampler),
           fq4=ShortRead::yield(sampler),
           fq5=ShortRead::yield(sampler),
           fq6=ShortRead::yield(sampler))

# Now generate temp a folder for the untrimmed fastq files

input <- paste0(tempdir(), "/seqpac_temp/")
if(grepl("windows", .Platform$OS.type)){
 input <- gsub( "\\\\\\\\", "/", input)
}

# Only for autonomous example we must empty the folder bofore creating:
unlink(input, recursive = TRUE)
dir.create(input, showWarnings=FALSE, recursive=TRUE)


# And then write the random fastq to the temp folder
for (i in 1:length(fqs)){
 input_file <- paste0(input, names(fqs)[i], ".fastq.gz")
 ShortRead::writeFastq(fqs[[i]], input_file, mode="w", 
                       full=FALSE, compress=TRUE)
}

# Run make_trim using NEB-next adaptor

list.files(input) #before

prog_report  <-  make_trim(
       input=input, output=input, 
       threads=1, check_mem=FALSE, 
       adapt_3_set=c(type="hard_rm", min=10, mismatch=0.1), 
       adapt_3="AGATCGGAAGAGCACACGTCTGAACTCCAGTCACTA", 
       polyG=c(type="hard_trim", min=20, mismatch=0.1),
       seq_range=c(min=14, max=70),
       quality=c(threshold=20, percent=0.8))
       
list.files(input) #after 
 
# How did it go? Check progress report:  
prog_report
     
}
\seealso{
\url{https://cutadapt.readthedocs.io/en/stable/} for download and
documentation on cutadapt.
\url{http://hannonlab.cshl.edu/fastx_toolkit/commandline.html} for download
and documentation on fastq_quality_filter. \url{https://github.com/Danis102}
for updates on seqpac.

Other PAC generation: 
\code{\link{PAC_check}()},
\code{\link{make_PAC}()},
\code{\link{make_counts}()},
\code{\link{make_pheno}()},
\code{\link{make_trim}()},
\code{\link{merge_lanes}()},
\code{\link{progress_report}()}
}
\concept{PAC generation}
