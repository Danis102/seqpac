% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/make_counts.R
\name{make_counts}
\alias{make_counts}
\title{Make raw Counts table from Sports output}
\usage{
make_counts(
  input,
  type = "fastq",
  trimming = NULL,
  threads = 1,
  plot = TRUE,
  parse = "default",
  evidence = c(experiment = 2, sample = 1),
  save_temp = FALSE
)
}
\arguments{
\item{input}{If type="fastq" the input is a path to a directory containing
input fastq-files. The script will recursively search this directory for
the .fastq|.fastq.gz extension. If type="sports" input is a list containing
imported data frames from Sports output. This list can be generated using
\code{import_sports}.}

\item{type}{Character indicating what input that should be used. If
type="fastq", the scripts will generate a count table based on fastq files
stored in the input path. If type="sports", a count table is generated from
a list object created using \code{import_sports} contain imported sports
output files .}

\item{trimming}{Character indicating what type of trimming tool that should
be used. If \code{trimming="seqpac"}, fastq files will be sent to the
\code{make_trim} function in seqpac, while if \code{trimming="cutadapt"}
fastq files will be sent to the \code{make_cutadapt} function. Note that
\code{trimming="seqpac"} runs independently of external software, while
\code{trimming="cutadapt"} is dependent on an externally installed version
of cutadapt. Trimmed fastq files are stored temporarily in the systems
default temporary folder. Please, run \code{make_trim} and
\code{make_cutadapt} seperately for perminant storaged options, or set
\code{save_temp=TRUE} to avoid that \code{make_counts} will delete all
temporary files.  As default trimming=NULL, which indicates that input
fastq files has already been trimmed.}

\item{threads}{Integer stating the number of parallell jobs. Note, that
reading multiple fastq files drains memory fast, using up to 10Gb per fastq
file. To avoid crashing the system due to memory shortage, make sure that
each thread on the machine have at least 10 Gb of memory availabe, unless
your fastq files are very small.Use \code{parallel::detectcores()} to see
available threads on the machine.}

\item{parse}{Command strings defining the command that should be parsed to
\code{make_trim} or \code{make_cutadapt}. This will allow you to customize
your timming according to 3' adaptor sequence and platform specifics etc.
See examples below. Please see manuals for \code{make_trim} \code{make_cutadapt}}

\item{evidence}{evidence=c(experiment=2, sample=1)}

\item{save_temp}{Logical whether temporary files (including trimmed fastq
files) should be saved or not. Note, the function will print the path to
the temprorary folder in the console.}
}
\value{
type="fastq": Data frame (a count table) with sequence counts across
all samples of sequences that occured at least two independent samples.

type="sports" Using the weakly filtered master annotation file (anno)
generated by the \code{make_anno} function, \code{make_counTable} will
extract the target sequences in anno from sports_lst and merge the counts
into one single data.frame (raw countTable). The output data.frame will ahve
rownames matching the original master annotation file.
}
\description{
\code{make_counts} uses parallel processing to generate a raw countTable.
}
\details{
Given a list of imported Sports output data.frames (generated by
\code{import_sports}), and an annotation file (generated by \code{make_anno}
this function will generate a raw countTable (columns=sample, rows=sequence).
}
\examples{
 library(seqpac)
 
 ############################################################ 
 ### Sports import 
 
 countTable <- make_counts(input = <name_of_your_imported_sports_list>,
                           anno    = <name_of_your_annotation_dataframe>,
                           threads       = <number_of_independent_evidence>,
                           )

 countTable <- make_count(sports_lst = sports_lst, anno=anno, threads=12)
  
############################################################ 
### Seqpac fastq trimming with the make_trim function 
### using default settings for NEBNext small RNA adaptor 

input = "/data/Data_analysis/Projects/Drosophila/Other/IOR/Jan_IOR_200130/Data/Single/Merged_fastq/"
input = system.file("extdata", package = "seqpac", mustWork = TRUE)

counts  <- make_counts(input, threads=6, parse="default_neb",
                       type="fastq", trimming="seqpac", plot=TRUE,
                       evidence=c(experiment=2, sample=1))     
    
     
############################################################      
### Seqpac trimming using the make_trim function
### using user settings parsed to make_trim
 
# Make a parse list (see ?make_trim):  
parse = list(adapt_3_set=c(type="hard_save", min=10, mismatch=0.1),
             adapt_3="AGATCGGAAGAGCACACGTCTGAACTCCAGTCACTA",
             polyG=c(type="hard_trim", min=10, mismatch=0.1),
             seq_range=c(min=14, max=70),
             quality=c(threshold=20, percent=0.8))
               
counts  <-  make_counts(input, threads=6,
                        type="fastq", trimming="seqpac",
                        parse=parse, 
                        evidence=c(experiment=2, sample=1))           
  
  
############################################################      
### Seqpac trimming using the make_cutadapt function
### (Important: Needs an external installations of cutadapt and fastq_quality_filter) 

 input <- system.file("extdata", package = "seqpac", mustWork = TRUE)
 
 # Parse for make_cutadapt is a list of 2 character string expressions.
 # The first is parsed to cutadapt and the other to fastq_quality_filter 
 # For parallel processes '-j 1' is recommended since seqpac will   
 # parallelize across samples and not within.
 # Run system("cutadapt -h") and system("fastq_quality_filter -h") for more options.
 
 parse = list(cutadapt="-j 1 -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCACAT --discard-untrimmed --nextseq-trim=20 -O 10 -m 14 -M 70",
              fastq_quality_filter="-q 20 -p 80")
 
 counts  <-  make_counts(input, threads=6,
                        type="fastq", trimming="cutadapt",
                        parse=parse, 
                        evidence=c(experiment=2, sample=1))   
 
 
 ## 2 evidence over two indepenent samples, saving single sample sequences reaching 10 counts
 test <- make_counts(input=input, type=type, evidence=c(experiment=2, sample=10), threads=threads, cutadpt=TRUE, parse=parse)
 extras <- apply(test$counts, 1, function(x){sum(x==0)})
 test$counts[extras==5,]  # No single sample sequence reaches 10 counts
 
 
 ## 2 evidence over two indepenent samples, saving single sample sequences reaching 3 counts 
 test <- make_counts(input=input, type=type, evidence=c(experiment=2, sample=3), threads=threads, cutadpt=TRUE, parse=parse)  
 extras <- apply(test$counts, 1, function(x){sum(x==0)})
 test$counts[extras==5,] # A few hundred single sample sequences reach 3 counts
 
 
 
 ##############################
 input <-  "/data/Data_analysis/Projects/Drosophila/Other/IOR/"
 parse_tag = list(  Long="cutadapt -j 1 -g TGGCAACGATC -O 5 -m 5", 
                        Short="cutadapt -j 1 -g TGGGATC -O 5 -m 5")
                        
 target_tag = list(  Long= gsub("_2", "-2", Ph_grps$Sample[Ph_grps$Tag_type \%in\% "Long"]),
                      Short= gsub("_2", "-2", Ph_grps$Sample[Ph_grps$Tag_type \%in\% "Short"]))
 
 test <- make_counts(input=input, type=type, threads=threads, cutadpt=TRUE, parse=parse, tag=tag, parse_tag=parse_tag, target_tag=target_tag)
 
 
 #'  Ph_grps <- read.delim("/data/Data_analysis/Projects/Drosophila/Other/IOR/Jan_IOR_200130/Groups_data.txt", header=TRUE)
 Ph_grps$Sample <-  gsub("_d|_s", "", Ph_grps$Sample_ID)
 Ph_grps <- Ph_grps[!duplicated(Ph_grps$Sample),]
 Ph_grps$Tag_type <- ifelse(grepl("Long", Ph_grps$Method), "Long", 
                             ifelse(grepl("Short", Ph_grps$Method), "Short", NA))
 
}
\seealso{
\url{https://github.com/junchaoshi/sports1.0} for download and
  documentation about running Sports. \url{https://github.com/Danis102} for
  updates on the current package.

Other PAC generation: 
\code{\link{import_sports}()},
\code{\link{make_PAC}()},
\code{\link{make_anno}()},
\code{\link{make_counts_dep}()},
\code{\link{make_cutadapt}()},
\code{\link{make_pheno}()},
\code{\link{make_trim}()},
\code{\link{progress_report}()}
}
\concept{PAC generation}
