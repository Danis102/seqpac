% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/make_counts.R
\name{make_counts}
\alias{make_counts}
\title{Make raw Counts table from Sports output}
\usage{
make_counts(
  input,
  type = "fastq",
  trimming = NULL,
  threads = 1,
  plot = TRUE,
  parse = "default",
  evidence = c(experiment = 2, sample = 1),
  save_temp = FALSE
)
}
\arguments{
\item{input}{If type="fastq" the input is a path to a directory containing
input fastq-files. The script will recursively search this directory for
the .fastq|.fastq.gz extension. If type="sports" input is a list containing
imported data frames from Sports output. This list can be generated using
\code{import_sports}.}

\item{type}{Character indicating what input that should be used. If
type="fastq", the scripts will generate a count table based on fastq files
stored in the input path. If type="sports", a count table is generated from
a list object created using \code{import_sports} contain imported sports
output files .}

\item{threads}{Integer stating the number of parallell jobs. Note, that
reading multiple fastq files drains memory fast, using up to 10Gb per fastq
file. To avoid crashing the system due to memory shortage, make sure that
each thread on the machine have at least 10 Gb of memory availabe, unless
your fastq files are very small.Use \code{parallel::detectcores()} to see
available threads on the machine.}

\item{parse}{Command strings defining the command that should be parsed to
cutadapt using the system function in R. This will allow you to customize
your timming according to 3' adaptor sequence and platform specifics etc.
See examples below. Important: Do not include the two last options in
cutadapt: -o (output path) and -i (input path). These will be generated
automatically.}

\item{cutadpt}{Logical indicating if fastq files should be parsed to cutadapt
and fastq_quality_filter (only available in Linux) for adaptor trimming and
filtering prior to compiling a count table. If cutadpt=FALSE, the input
path must contain already trimmed and quality filtered fastq files. If
cutadpt=TRUE, trimming will be carried out using the commands in "parse",
while quality filtering will be done using the following command:
"fastq_quality_filter -q 20 -p 80 -v". Trimmed and filtered fastq files
will be temporarly stored in "tmp/seqpac/", but will be deleted after the
script has completed.}

\item{tag}{Logical indicating whether 5' tagging has been used. This is
specific to certain types of sequencing experiments, where beside a 3'
adaptor a 5' tag has been ligated to the sequencing library. If tag=TRUE, a
5' tag will be searched for only in the samples specified in 'target_tag'
using the commands indicated in 'parse_tag'. Note that target_tag and
parse_tag are lists, thus groups of samples can have different commands
parsed to them. Example of how this can be done see below. Note that
parsing these commands will be done after the 3' adaptor sequence has been
trimmed off. This will be done on the fastq files If tag=FALSE, this step
will be passed.}

\item{parse_tag}{A named list of command strings. Each object contains the
command that are to be parsed to cutadapt, for splitting the input fastq
file specified in 'target_tag' into fastq files containg (_tag.fastq) and
not containing (_notag.fastq) the 5' tag. The 5' tag will also be trimmed
from _tag.fastq files. Important: Do not include the two last options in
cutadapt: -o (output path) and -i (input path). These will be generated
automatically. Default=NULL.}

\item{target_tag}{A named list of character vectors. Each vector should
contain the the input fastq file names of which 5' tagging have been used.
If different 5' tags, with different sequences, has been ligated to
different samples,  this can be specified objects with the same names in
'target_tag' and 'parse_tag' having the same names.  For example, if
target_tag$short contains the fastq file names of sample_A and sample_D,
the command in parse_tag$short will be applied only on these samples.
Samples missing from 'target_tag', will pass 5' tagging. For an examples
see below. Default=NULL.}
}
\value{
type="fastq": Data frame (a count table) with sequence counts across
all samples of sequences that occured at least two independent samples.

type="sports" Using the weakly filtered master annotation file (anno)
generated by the \code{make_anno} function, \code{make_counTable} will
extract the target sequences in anno from sports_lst and merge the counts
into one single data.frame (raw countTable). The output data.frame will ahve
rownames matching the original master annotation file.
}
\description{
\code{make_counts} uses parallel processing to generate a raw countTable.
}
\details{
Given a list of imported Sports output data.frames (generated by
\code{import_sports}), and an annotation file (generated by \code{make_anno}
this function will generate a raw countTable (columns=sample, rows=sequence).
}
\examples{
 library(seqpac)
 
 ############################################################ 
 ### Sports import 
 
 countTable <- make_counts(input = <name_of_your_imported_sports_list>,
                           anno    = <name_of_your_annotation_dataframe>,
                           threads       = <number_of_independent_evidence>,
                           )

 countTable <- make_count(sports_lst = sports_lst, anno=anno, threads=12)
  
############################################################ 
### Seqpac fastq trimming with the make_trim function 
### using default settings for NEBNext small RNA adaptor 

input = "/data/Data_analysis/Projects/Drosophila/Other/IOR/Jan_IOR_200130/Data/Single/Merged_fastq/"
input = system.file("extdata", package = "seqpac", mustWork = TRUE)

counts  <- make_counts(input, threads=6, parse="default",
                       type="fastq", trimming="seqpac", plot=TRUE,
                       evidence=c(experiment=2, sample=1))     
    
     
############################################################      
### Seqpac trimming using the make_trim function
### using user settings parsed to make_trim
 
# Make a parse list (see ?make_trim):  
parse = list(adapt_3_set=c(type="hard_save", min=10, mismatch=0.1),
             adapt_3="AGATCGGAAGAGCACACGTCTGAACTCCAGTCACTA",
             polyG=c(type="hard_trim", min=10, mismatch=0.1),
             seq_range=c(min=14, max=70),
             quality=c(threshold=20, percent=0.8))
               
counts  <-  make_counts(input, threads=6,
                        type="fastq", trimming="seqpac",
                        parse=parse, 
                        evidence=c(experiment=2, sample=1))           
  
  
############################################################      
### Seqpac trimming using the make_cutadapt function
### (Important: Needs an external installations of cutadapt and fastq_quality_filter) 

 input <- system.file("extdata", package = "seqpac", mustWork = TRUE)
 
 # Parse for make_cutadapt is a list of 2 character string expressions.
 # The first is parsed to cutadapt and the other to fastq_quality_filter 
 # For parallel processes '-j 1' is recommended since seqpac will   
 # parallelize across samples and not within.
 # Run system("cutadapt -h") and system("fastq_quality_filter -h") for more options.
 
 parse = list(cutadapt="-j 1 -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCACAT --discard-untrimmed --nextseq-trim=20 -O 10 -m 14 -M 70",
              fastq_quality_filter="-q 20 -p 80")
 
 counts  <-  make_counts(input, threads=6,
                        type="fastq", trimming="cutadapt",
                        parse=parse, 
                        evidence=c(experiment=2, sample=1))   
 
 
 ## 2 evidence over two indepenent samples, saving single sample sequences reaching 10 counts
 test <- make_counts(input=input, type=type, evidence=c(experiment=2, sample=10), threads=threads, cutadpt=TRUE, parse=parse)
 extras <- apply(test$counts, 1, function(x){sum(x==0)})
 test$counts[extras==5,]  # No single sample sequence reaches 10 counts
 
 
 ## 2 evidence over two indepenent samples, saving single sample sequences reaching 3 counts 
 test <- make_counts(input=input, type=type, evidence=c(experiment=2, sample=3), threads=threads, cutadpt=TRUE, parse=parse)  
 extras <- apply(test$counts, 1, function(x){sum(x==0)})
 test$counts[extras==5,] # A few hundred single sample sequences reach 3 counts
 
 
 
 ##############################
 input <-  "/data/Data_analysis/Projects/Drosophila/Other/IOR/"
 parse_tag = list(  Long="cutadapt -j 1 -g TGGCAACGATC -O 5 -m 5", 
                        Short="cutadapt -j 1 -g TGGGATC -O 5 -m 5")
                        
 target_tag = list(  Long= gsub("_2", "-2", Ph_grps$Sample[Ph_grps$Tag_type \%in\% "Long"]),
                      Short= gsub("_2", "-2", Ph_grps$Sample[Ph_grps$Tag_type \%in\% "Short"]))
 
 test <- make_counts(input=input, type=type, threads=threads, cutadpt=TRUE, parse=parse, tag=tag, parse_tag=parse_tag, target_tag=target_tag)
 
 
 #'  Ph_grps <- read.delim("/data/Data_analysis/Projects/Drosophila/Other/IOR/Jan_IOR_200130/Groups_data.txt", header=TRUE)
 Ph_grps$Sample <-  gsub("_d|_s", "", Ph_grps$Sample_ID)
 Ph_grps <- Ph_grps[!duplicated(Ph_grps$Sample),]
 Ph_grps$Tag_type <- ifelse(grepl("Long", Ph_grps$Method), "Long", 
                             ifelse(grepl("Short", Ph_grps$Method), "Short", NA))
 
}
\seealso{
\url{https://github.com/junchaoshi/sports1.0} for download and
  documentation about running Sports. \url{https://github.com/Danis102} for
  updates on the current package.

Other PAC generation: 
\code{\link{import_sports}()},
\code{\link{make_PAC}()},
\code{\link{make_anno}()},
\code{\link{make_counts_dep}()},
\code{\link{make_cutadapt}()},
\code{\link{make_pheno}()},
\code{\link{make_trim}()},
\code{\link{progress_report}()}
}
\concept{PAC generation}
